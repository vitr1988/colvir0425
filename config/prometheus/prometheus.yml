  # my global config
  global:
    scrape_interval:     5s # Set the scrape interval to every 5 seconds. Default is every 1 minute.
    evaluation_interval: 5s # Evaluate rules every 5 seconds. The default is every 1 minute.
    # scrape_timeout is set to the global default (10s).

    # Attach these labels to any time series or alerts when communicating with
    # external systems (federation, remote storage, Alertmanager).
    external_labels:
      monitor: 'colvir-monitor'

  # Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
  rule_files:
  # - "first.rules"
  # - "second.rules"

  # A scrape configuration containing exactly one endpoint to scrape:
  # Here it's Prometheus itself.
  scrape_configs:
    # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
    - job_name: 'base'
      metrics_path: '/app/actuator/prometheus'
      static_configs:
        - targets: ['host.docker.internal:8090']

    - job_name: 'mongo'
      metrics_path: '/mongo/actuator/prometheus'
      static_configs:
        - targets: ['host.docker.internal:8095']

    - job_name: 'classic-web'
      metrics_path: '/web/actuator/prometheus'
      static_configs:
        - targets: ['host.docker.internal:8085']

    - job_name: 'prometheus'
      # metrics_path defaults to '/metrics'
      # scheme defaults to 'http'.
      static_configs:
        - targets: ['localhost:9090']

            #- job_name: 'docker'
            # metrics_path defaults to '/metrics'
          # scheme defaults to 'http'.

